# Imports
import os.path

import numpy as np

from .annotation_db import *


# Feature handling
def get_raw_features():
    """Load in features file generated by <https://github.com/evhub/transfer_learning_music>."""
    return np.load(FEATURES_FILE)

def split_arr(arr):
    """Split the given 2D array in half."""
    n, _ = arr.shape
    a, b = arr[:n//2], arr[n//2:]
    assert a.shape == b.shape, (a.shape, b.shape)
    return a, b

def load_features():
    """Return a tuple of (ref_features, query_features) where each array is in index_db() order."""
    return split_arr(get_raw_features())

def read_features():
    """Return an iterator of all (label, query_index, beat_index, ref_feature_array, query_feature_array) tuples.
    Since this function is implemented as a generator, no work is done until it is iterated over."""
    ref_features, query_features = load_features()
    for (label, query_index, beat_index, ref_path, query_path), ref_feature_array, query_feature_array in zip(
        index_db(),
        ref_features,
        query_features,
    ):
        yield label, query_index, beat_index, ref_feature_array, query_feature_array


# Feature statistics
def mad(arr, axis):
    """Compute the mean absolute deviation of the given array along the given axis."""
    mean = np.mean(arr, axis=axis)
    return np.mean(np.abs(arr - mean), axis=axis)

def ave_dist(a, b, axis):
    """Compute the average distance between a and b along the given axis."""
    return np.mean(np.abs(a - b), axis=axis)

def scaled_dist(a, b, scale_by, axis=0):
    """Find the mean distance between a and b with the given scaling along the given axis."""
    dist = ave_dist(a, b, axis=axis)
    return np.mean(dist/scale_by)

def summarize_features():
    """Print a summary of the extracted features."""
    raw_features = get_raw_features()
    n, num_feats = raw_features.shape

    stds = np.std(raw_features, axis=0)
    mads = mad(raw_features, axis=0)

    ref_features, query_features = load_features()
    ref_query_stds = scaled_dist(ref_features, query_features, stds)
    ref_query_mads = scaled_dist(ref_features, query_features, mads)

    rand_ref, rand_query = np.random.permutation(ref_features), np.random.permutation(query_features)
    rand_ref_query_stds = scaled_dist(rand_ref, rand_query, stds)
    rand_ref_query_mads = scaled_dist(rand_ref, rand_query, mads)

    rand1, rand2 = split_arr(np.random.permutation(raw_features))
    rand_stds = scaled_dist(rand1, rand2, stds)
    rand_mads = scaled_dist(rand1, rand2, mads)

    print("""
The database contains {} entries ({} each reference and query)
with {} features per entry. Reference and query feature arrays
are an average of
\t{}
standard deviations apart and
\t{}
mean absolute deviations apart. For comparison, if we randomly
permute the reference and query features they are an average of
\t{}
standard deviations apart and
\t{}
mean absolute deviations apart. Alternatively, if we randomly
partition the whole dataset, we get that the two partitions are
an average of
\t{}
standard deviations apart and
\t{}
mean absolute deviations apart.
""".format(
    n, n//2,
    num_feats,
    ref_query_stds,
    ref_query_mads,
    rand_ref_query_stds,
    rand_ref_query_mads,
    rand_stds,
    rand_mads,
))
